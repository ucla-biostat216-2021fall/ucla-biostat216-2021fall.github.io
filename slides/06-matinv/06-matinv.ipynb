{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Linear-equations-and-matrix-inverses-(BV-Chapter-11)\" data-toc-modified-id=\"Linear-equations-and-matrix-inverses-(BV-Chapter-11)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Linear equations and matrix inverses (BV Chapter 11)</a></div><div class=\"lev2 toc-item\"><a href=\"#Left-and-right-inverses\" data-toc-modified-id=\"Left-and-right-inverses-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Left and right inverses</a></div><div class=\"lev2 toc-item\"><a href=\"#When-does-a-matrix-have-a-left-or-right-inverse?\" data-toc-modified-id=\"When-does-a-matrix-have-a-left-or-right-inverse?-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>When does a matrix have a left or right inverse?</a></div><div class=\"lev2 toc-item\"><a href=\"#Generalized-inverse-and-Moore-Penrose-inverse\" data-toc-modified-id=\"Generalized-inverse-and-Moore-Penrose-inverse-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Generalized inverse and Moore-Penrose inverse</a></div><div class=\"lev2 toc-item\"><a href=\"#Linear-equations\" data-toc-modified-id=\"Linear-equations-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Linear equations</a></div><div class=\"lev2 toc-item\"><a href=\"#Application:-least-squares\" data-toc-modified-id=\"Application:-least-squares-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Application: least squares</a></div><div class=\"lev2 toc-item\"><a href=\"#Projection\" data-toc-modified-id=\"Projection-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Projection</a></div><div class=\"lev2 toc-item\"><a href=\"#An-example-of-generalized-inverses\" data-toc-modified-id=\"An-example-of-generalized-inverses-17\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>An example of generalized inverses</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear equations and matrix inverses (BV Chapter 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left and right inverses\n",
    "\n",
    "- A **left inverse** of $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ is any matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times m}$ such that \n",
    "$$\n",
    "\\mathbf{X} \\mathbf{A} = \\mathbf{I}_n.\n",
    "$$\n",
    "$\\mathbf{A}$ is **left invertible** if it has at least one left inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Matrix{Int64}:\n",
       " -3  -4\n",
       "  4   6\n",
       "  1   1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 3x2 matrix\n",
    "A = [-3 -4; 4 6; 1 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Rational{Int64}}:\n",
       " -11//9  -10//9   16//9\n",
       "   7//9    8//9  -11//9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X1 is a left inverse of A\n",
    "X1 = [-11//9 -10//9 16//9; 7//9 8//9 -11//9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 1  0\n",
       " 0  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int.(X1 * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Rational{Int64}}:\n",
       " 0//1  -1//2   3//1\n",
       " 0//1   1//2  -2//1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B2 is another left inverse of A\n",
    "X2 = [0 -1//2 3; 0 1//2 -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 1  0\n",
       " 0  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int.(X2 * A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **right inverse** of $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ is any matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times m}$ such that \n",
    "$$\n",
    "\\mathbf{A} \\mathbf{X} = \\mathbf{I}_m.\n",
    "$$\n",
    "$\\mathbf{A}$ is **right invertible** if it has at least one right inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Int64}:\n",
       " 1  0  1\n",
       " 0  1  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 2x3 matrix\n",
    "A = [1 0 1; 0 1 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Matrix{Rational{Int64}}:\n",
       "  1//2  -1//2\n",
       " -1//2   1//2\n",
       "  1//2   1//2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X1 is a right inverse of A\n",
    "X1 = [1//2 -1//2; -1//2 1//2; 1//2 1//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 1  0\n",
       " 0  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int.(A * X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Matrix{Int64}:\n",
       " 1  0\n",
       " 0  1\n",
       " 0  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X2 is anoter right inverse of A\n",
    "X2 = [1 0; 0 1; 0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 1  0\n",
       " 0  1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int.(A * X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Matrix{Int64}:\n",
       " 1  -1\n",
       " 0   0\n",
       " 0   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X3 is yet anoter right inverse of A\n",
    "X3 = [1 -1; 0 0; 0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 1  0\n",
       " 0  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int.(A * X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{X}$ is a left inverse of $\\mathbf{A}$ if and only if $\\mathbf{X}'$ is a right inverse of $\\mathbf{A}'$.\n",
    "$$\n",
    "\\mathbf{A}' \\mathbf{X}' = (\\mathbf{X} \\mathbf{A})' = \\mathbf{I}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When does a matrix have a left or right inverse?\n",
    "\n",
    "- For $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$,  \n",
    "    1. $\\mathbf{A}$ has a right inverse if and only if $\\text{rank}(\\mathbf{A}) = m$, or equivalently, $\\mathbf{A}$ has full row rank.  \n",
    "    2. $\\mathbf{A}$ has a left inverse if and only if $\\text{rank}(\\mathbf{A}) = n$, or equivalently, $\\mathbf{A}$ has full column rank.\n",
    "\n",
    "    Proof of (1). For the _if_ part, since column rank equals row rank, the columns of $\\mathbf{A}$ span $\\mathbb{R}^m$. Then for each column $\\mathbf{e}_j$ of $\\mathbf{I}_m$, there exists $\\mathbf{c}_j$ such that $\\mathbf{A} \\mathbf{c}_j = \\mathbf{e}_j$. Collecting $\\mathbf{c}_j$ as columns of $\\mathbf{C}$, we proved $\\mathbf{A} \\mathbf{C} = \\mathbf{I}$.  \n",
    "    \n",
    "    For the _only if_ part, since $\\mathbf{A} \\mathbf{C} = \\mathbf{I}_m$, we have $m \\ge \\text{rank}(\\mathbf{A}) \\ge \\text{rank}(\\mathbf{A} \\mathbf{C}) = \\text{rank}(\\mathbf{I}_m) = m$. Thus $\\text{rank}(\\mathbf{A}) = m$.\n",
    "    \n",
    "    Proof of (2). Apply (1) to $\\mathbf{A}'$.  \n",
    "\n",
    "- If $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ has a left inverse $\\mathbf{X}$ and a right inverse $\\mathbf{Y}$, then  \n",
    "    1. $\\mathbf{A}$ must be a square, nonsingular matrix, and $\\mathbf{X} = \\mathbf{Y}$.  \n",
    "    2. $\\mathbf{A}$ has a unique left inverse and a unique right inverse, which we call the **inverse** of $\\mathbf{A}$ and denote it by $\\mathbf{A}^{-1}$.\n",
    "            \n",
    "     Proof: From previous theorem, we have $m = \\text{rank}(\\mathbf{A}) = n$. Thus $\\mathbf{A}$ is square, and $\\mathbf{X}$ and $\\mathbf{Y}$ as well. Then\n",
    "$$\n",
    "    \\mathbf{X} = \\mathbf{X} \\mathbf{I}_n = \\mathbf{X} (\\mathbf{A} \\mathbf{Y}) = (\\mathbf{X} \\mathbf{A}) \\mathbf{Y} = \\mathbf{Y}.\n",
    "$$\n",
    "To show the uniqueness of left inverse, suppose $\\mathbf{Z}$ is another left inverse. Then \n",
    "$$\n",
    "    \\mathbf{Z} \\mathbf{A} = \\mathbf{I}_n = \\mathbf{X} \\mathbf{A}.\n",
    "$$\n",
    "Multiplying both sides on the right by right inverse $\\mathbf{Y}$, we obtain $\\mathbf{Z} = \\mathbf{X}$. Thus left inverse is unique. Uniqueness of right inverse is shown in a similar fashion. \n",
    "     \n",
    "- Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$. Then\n",
    "\n",
    "    1. $\\mathbf{A}$ has full column rank if and only if $\\mathbf{A}'\\mathbf{A}$ is nonsingular. In this case, $(\\mathbf{A}'\\mathbf{A})^{-1} \\mathbf{A}'$ is a left inverse of $\\mathbf{A}$.  \n",
    "    \n",
    "    2. $\\mathbf{A}$ has full row rank if and only if $\\mathbf{A}\\mathbf{A}'$ is nonsingular. In this case, $\\mathbf{A}'(\\mathbf{A}'\\mathbf{A})^{-1}$ is a right inverse of $\\mathbf{A}$. \n",
    "    \n",
    "    Proof: easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Int64}:\n",
       " -1   1  -3\n",
       "  1  -1   1\n",
       "  2   2   2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [-1 1 -3; 1 -1 1; 2 2 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  0.5   1.0  0.25\n",
       " -0.0  -0.5  0.25\n",
       " -0.5  -0.5  0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A⁻¹ = inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 1.0  0.0  0.0\n",
       " 0.0  1.0  0.0\n",
       " 0.0  0.0  1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A⁻¹ * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 1.0  0.0  0.0\n",
       " 0.0  1.0  0.0\n",
       " 0.0  0.0  1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * A⁻¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized inverse and Moore-Penrose inverse\n",
    "\n",
    "- Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$. A matrix $\\mathbf{G} \\in \\mathbb{R}^{n \\times m}$ is called the **Moore-Penrose inverse** or **MP inverse** of $\\mathbf{A}$ if it satisifes following four conditions:   \n",
    "    (1) $\\mathbf{A} \\mathbf{G} \\mathbf{A} = \\mathbf{A}$. $\\quad \\quad$ (_generalized inverse_, $g_1$ inverse, or _inner pseudo-inverse_)  \n",
    "    (2) $\\mathbf{G} \\mathbf{A} \\mathbf{G} = \\mathbf{G}$. $\\quad \\quad$ (_outer pseudo-inverse_)  \n",
    "    (3) $(\\mathbf{A} \\mathbf{G})' = \\mathbf{A} \\mathbf{G}$.  \n",
    "    (4) $(\\mathbf{G} \\mathbf{A})' = \\mathbf{G} \\mathbf{A}$.  \n",
    "    We shall denote the **Moore-Penrose inverse** of $\\mathbf{A}$ by $\\mathbf{A}^+$.\n",
    "\n",
    "- Any matrix $\\mathbf{G} \\in \\mathbb{R}^{n \\times m}$ that satisfies (1) is called a **generalized inverse**, or **$g_1$ inverse**, or **inner pseudo-inverse**. Denoted by $\\mathbf{A}^-$ or $\\mathbf{A}^g$.\n",
    "\n",
    "- Any matrix $\\mathbf{G} \\in \\mathbb{R}^{n \\times m}$ that satisfies (1)+(2) is called a **reflective generalized inverse**, or **$g_2$ inverse**, or **outer pseudo-inverse**. Denoted by $\\mathbf{A}^*$.\n",
    "\n",
    "- The **Moore-Penrose inverse** of any matrix $\\mathbf{A}$ exists and is unique. \n",
    "\n",
    "    Proof of uniqueness: Let $\\mathbf{G}_1, \\mathbf{G}_2 \\in \\mathbb{R}^{n \\times m}$ be two matrices satisfying properties (1)-(4). Then  \n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{G}_1 = (\\mathbf{A} \\mathbf{G}_1)' = \\mathbf{G}_1' \\mathbf{A}' = \\mathbf{G}_1' (\\mathbf{A} \\mathbf{G}_2 \\mathbf{A})' = \\mathbf{G}_1' \\mathbf{A}' \\mathbf{G}_2' \\mathbf{A}' = (\\mathbf{A} \\mathbf{G}_1)' (\\mathbf{A} \\mathbf{G}_2)' = \\mathbf{A} \\mathbf{G}_1 \\mathbf{A} \\mathbf{G}_2 = \\mathbf{A} \\mathbf{G}_2.\n",
    "$$\n",
    "Similarly,\n",
    "$$\n",
    "    \\mathbf{G}_1 \\mathbf{A} = (\\mathbf{G}_1 \\mathbf{A})' = \\mathbf{A}' \\mathbf{G}_1' = (\\mathbf{A} \\mathbf{G}_2 \\mathbf{A})' \\mathbf{G}_1' = \\mathbf{A}' \\mathbf{G}_2' \\mathbf{A}' \\mathbf{G}_1' = (\\mathbf{G}_2 \\mathbf{A})' (\\mathbf{G}_1 \\mathbf{A})' = \\mathbf{G}_2 \\mathbf{A} \\mathbf{G}_1 \\mathbf{A} = \\mathbf{G}_2 \\mathbf{A}.\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "    \\mathbf{G}_1 = \\mathbf{G}_1 \\mathbf{A} \\mathbf{G}_1 = \\mathbf{G}_1 \\mathbf{A} \\mathbf{G}_2 = \\mathbf{G}_2 \\mathbf{A} \\mathbf{G}_2 = \\mathbf{G}_2.\n",
    "$$\n",
    "    \n",
    "    Proof of existence: TODO later. We construct a matrix that satisfies (1)-(4) using the singular value decomposition (SVD) of $\\mathbf{A}$.\n",
    "    \n",
    "- Following are true: \n",
    "    1. $(\\mathbf{A}^-)'$ is a generalized inverse of $\\mathbf{A}'$. \n",
    "    2. $(\\mathbf{A}')^+ = (\\mathbf{A}^+)'$.  \n",
    "    3. For any nonzero $k$, $(1/k) \\mathbf{A}^-$ is a generalized inverse of $k \\mathbf{A}$.  \n",
    "    4. $(k \\mathbf{A})^+ = (1/k) \\mathbf{A}^+$.\n",
    "\n",
    "    Proof: Check properties (1)-(4).\n",
    "    \n",
    "- **Multiplication by generalized inverse does not change rank.**  \n",
    "    1. $\\mathcal{C}(\\mathbf{A}) = \\mathcal{C}(\\mathbf{A} \\mathbf{A}^-)$ and $\\mathcal{C}(\\mathbf{A}') = \\mathcal{C}((\\mathbf{A}^- \\mathbf{A})')$.  \n",
    "    2. $\\text{rank}(\\mathbf{A}) = \\text{rank}(\\mathbf{A} \\mathbf{A}^-) = \\text{rank}(\\mathbf{A}^- \\mathbf{A})$. \n",
    "    \n",
    "    Proof of 1: We already know $\\mathcal{C}(\\mathbf{A}) \\supseteq \\mathcal{C}(\\mathbf{A} \\mathbf{A}^-)$. Now since $\\mathbf{A} = \\mathbf{A} \\mathbf{A}^- \\mathbf{A}$, we also have $\\mathcal{C}(\\mathbf{A}) \\subseteq \\mathcal{C}(\\mathbf{A} \\mathbf{A}^-)$.   \n",
    "    Proof of 2: By definition of rank.  \n",
    "    \n",
    "- **Generalized inverse has equal or larger rank.**  $\\text{rank}(\\mathbf{A}^-) \\ge \\text{rank}(\\mathbf{A})$.  \n",
    "\n",
    "    Proof: $\\text{rank}(\\mathbf{A}) = \\text{rank}(\\mathbf{A}\\mathbf{A}^- \\mathbf{A}) \\le \\text{rank}(\\mathbf{A}\\mathbf{A}^-) \\le \\text{rank}(\\mathbf{A}^-)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear equations\n",
    "\n",
    "- Solving linear system\n",
    "\\begin{eqnarray*}\n",
    "a_{11} x_1 + \\cdots + a_{1n} x_n &=& b_1 \\\\\n",
    "a_{21} x_1 + \\cdots + a_{2n} x_n &=& b_2 \\\\\n",
    "&\\vdots& \\\\\n",
    "a_{m1} x_1 + \\cdots + a_{mn} x_n &=& b_m\n",
    "\\end{eqnarray*}\n",
    "or\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{x} = \\mathbf{b},\n",
    "$$\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ (coefficient matrix), $\\mathbf{x} \\in \\mathbb{R}^n$ (solution vector), and $\\mathbf{b} \\in \\mathbb{R}^m$ (right hand side) is a central theme in linear algebra. \n",
    "\n",
    "We care about two fundamental questions: (1) when does the linear system has solution, and (2) how to characterize the solution set.\n",
    "\n",
    "- Left-invertible matrix: If $\\mathbf{X}$ is a left inverse of $\\mathbf{A}$, then\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{x} = \\mathbf{b}\n",
    "$$\n",
    "implies (multiplying both sizes of $\\mathbf{X}$)\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{X} \\mathbf{b}.\n",
    "$$\n",
    "There is _at most one_ solution. If there is a solution, it must be equal to $\\mathbf{X} \\mathbf{b}$.\n",
    "\n",
    "- Right-invertible matrix: If $\\mathbf{X}$ is a right inverse of $\\mathbf{A}$, then\n",
    "$$\n",
    "\\mathbf{A} (\\mathbf{X} \\mathbf{b}) = \\mathbf{b}.\n",
    "$$\n",
    "This says there is at least one solution $\\mathbf{x} = \\mathbf{X} \\mathbf{b}$.\n",
    "\n",
    "- Invertible matrix: If $\\mathbf{A}$ is invertible, then\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{x} = \\mathbf{b}\n",
    "$$\n",
    "implies (multiplying both sizes of $\\mathbf{A}^{-1}$)\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}.\n",
    "$$\n",
    "There is a _unique_ solution.\n",
    "\n",
    "- **When is there a solution?** The following statements are equivalent:  \n",
    "    1. The linear system $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ has a solution (**consistent**).  \n",
    "    2. $\\mathbf{b} \\in \\mathcal{C}(\\mathbf{A})$.  \n",
    "    3. $\\text{rank}((\\mathbf{A} : \\mathbf{b})) = \\text{rank}(\\mathbf{A})$.  \n",
    "    4. $\\mathbf{A} \\mathbf{A}^- \\mathbf{b} = \\mathbf{b}$ for any generalized inverse $\\mathbf{A}^-$.  \n",
    "    The last equivalence gives some intuition why $\\mathbf{A}^-$ is called an inverse.\n",
    "    \n",
    "    Proof: $1 \\Rightarrow 2 \\Rightarrow 3 \\Rightarrow 1$ is easy. We show $1 \\Rightarrow 4 \\rightarrow 1$.  \n",
    "    Proof of $1 \\Rightarrow 4$: If $\\tilde{\\mathbf{x}}$ is a solution, then\n",
    "$$\n",
    "    \\mathbf{b} = \\mathbf{A} \\tilde{\\mathbf{x}} = \\mathbf{A}\\mathbf{A}^- \\mathbf{A} \\tilde{\\mathbf{x}} = \\mathbf{A}\\mathbf{A}^- \\mathbf{b}.\n",
    "$$  \n",
    "    Proof of $4 \\Rightarrow 1$: Apparently $\\tilde{\\mathbf{x}} = \\mathbf{A}^- \\mathbf{b}$ is a solution.\n",
    "    \n",
    "- **What are the solutions?** Let's first consider the **homogeneous** system: $\\mathbf{A} \\mathbf{x} = \\mathbf{0}$.  Note **homogeneous** system is always consistent (why?)  \n",
    "\n",
    "    Theorem: $\\tilde{\\mathbf{x}}$ is a solution of $\\mathbf{A} \\mathbf{x} = \\mathbf{0}$ if and only if\n",
    "$$\n",
    "    \\tilde{\\mathbf{x}} = (\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}) \\mathbf{q}\n",
    "$$\n",
    "for some $\\mathbf{q} \\in \\mathbb{R}^n$.  \n",
    "    Rephrase of this theorem: $\\mathcal{N}(\\mathbf{A}) = \\mathcal{C}(\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A})$. \n",
    "    \n",
    "    Proof of \"if\" part: Regardless value of $\\mathbf{q}$, we have\n",
    "$$\n",
    "    \\mathbf{A} \\tilde{\\mathbf{x}} = \\mathbf{A} (\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}) \\mathbf{q} = (\\mathbf{A} - \\mathbf{A} \\mathbf{A}^- \\mathbf{A}) \\mathbf{q} = \\mathbf{O} \\mathbf{q} = \\mathbf{0}. \n",
    "$$  \n",
    "    Proof of \"only if\" part: If $\\tilde{\\mathbf{x}}$ is a solution, then we have \n",
    "$$\n",
    "    \\tilde{\\mathbf{x}} = (\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}) \\mathbf{q},\n",
    "$$\n",
    "where $\\mathbf{q} = \\tilde{\\mathbf{x}}$.  \n",
    "\n",
    "- **What are the solutions?** Now we can study the **inhomogeneous** system: $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$.\n",
    "\n",
    "    Theorem: If $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ is consistent, then $\\tilde{\\mathbf{x}}$ is a solution to $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ if and only if \n",
    "$$\n",
    "    \\tilde{\\mathbf{x}} = \\mathbf{A}^- \\mathbf{b} + (\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}) \\mathbf{q}\n",
    "$$\n",
    "for some $\\mathbf{q} \\in \\mathbb{R}^n$.  \n",
    "    Interpretation: \"a specific solution\" + \"a vector in $\\mathcal{N}(\\mathbf{A})$\".  \n",
    "    \n",
    "    Proof:\n",
    "\\begin{eqnarray*}\n",
    "    & & \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\\n",
    "    &\\Leftrightarrow& \\mathbf{A} \\mathbf{x} = \\mathbf{A} \\mathbf{A}^- \\mathbf{b} \\\\\n",
    "    &\\Leftrightarrow& \\mathbf{A} (\\mathbf{x} - \\mathbf{A}^- \\mathbf{b}) = \\mathbf{0} \\\\\n",
    "    &\\Leftrightarrow& \\mathbf{x} - \\mathbf{A}^- \\mathbf{b} \\in \\mathcal{N}(\\mathbf{A}) \\\\\n",
    "    &\\Leftrightarrow& \\mathbf{x} - \\mathbf{A}^- \\mathbf{b} = (\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}) \\mathbf{q} \\text{ for some } \\mathbf{q} \\in \\mathbb{R}^n \\\\\n",
    "    &\\Leftrightarrow& \\mathbf{x} = \\mathbf{A}^- \\mathbf{b} + (\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}) \\mathbf{q} \\text{ for some } \\mathbf{q} \\in \\mathbb{R}^n.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "- $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ is consistent **for all $\\mathbf{b}$** if and only if $\\mathbf{A}$ has full row rank.  \n",
    "\n",
    "    Proof of \"if\" part: If $\\mathbf{A}$ has full row rank, then the column rank of $\\mathbf{A}$ is $m$ and $\\mathcal{C}(\\mathbf{A}) = \\mathbb{R}^m$. Thus for any $\\mathbf{b} \\in \\mathbb{R}^m$, there exists a solution $\\mathbf{x}$.    \n",
    "    Proof of \"only if\" part: $\\mathbf{A} \\mathbf{A}^- \\mathbf{b} = \\mathbf{b}$ for all $\\mathbf{b} \\in \\mathbb{R}^m$. Take $\\mathbf{b} = \\mathbf{e}_i$ for $i=1,\\ldots,m$. We have $\\mathbf{A} \\mathbf{A}^- = \\mathbf{I}_m$. Thus \n",
    "$$\n",
    "    m = \\text{rank}(\\mathbf{I}_m) = \\text{rank}(\\mathbf{A} \\mathbf{A}^-) \\le \\text{rank}(\\mathbf{A}) \\le m.\n",
    "$$    \n",
    "\n",
    "- If $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ is consistent, then its solution is unique if and only if $\\mathbf{A}$ has full column rank. \n",
    "\n",
    "    Proof of \"if\" part: If there are two solutions $\\mathbf{A} \\mathbf{x}_1 = \\mathbf{b}$ and $\\mathbf{A} \\mathbf{x}_2 = \\mathbf{b}$, then $\\mathbf{A} (\\mathbf{x}_1 - \\mathbf{x}_2) = \\mathbf{0}$, i.e., $\\mathbf{x}_1 - \\mathbf{x}_2 \\in \\mathcal{N}(\\mathbf{A})$. By the rank-nullity theorem, the $\\mathcal{N}(\\mathbf{A}) = \\{\\mathbf{0}\\}$. Thus $\\mathbf{x}_1 = \\mathbf{x}_2$.  \n",
    "    Proof of \"only if\" part: By characterization of soultion set, uniqueness of solution implies $\\mathcal{N}(\\mathcal{A}) = \\{\\mathbf{0}\\}$. Then by the rank-nullity theorem, $\\mathbf{A}$ has full column rank.  \n",
    "    \n",
    "- If $\\mathbf{A}$ has full row and column rank, then $\\mathbf{A}$ is non-singular and the unique solution is $\\mathbf{A}^{-1} \\mathbf{b}$ for any $\\mathbf{b}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: least squares\n",
    "\n",
    "- Least squares problem:\n",
    "$$\n",
    "    \\text{minimize}_{\\boldsymbol{\\beta}} \\quad f(\\boldsymbol{\\beta}) = \\frac 12 \\|\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}\\|^2.\n",
    "$$\n",
    "Find the linear combination of columns of $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ that approximates $\\mathbf{y} \\in \\mathbb{R}^n$ best, or equivalently, find the vector in $\\mathcal{C}(\\mathbf{X})$ that approximates $\\mathbf{y}$ best. \n",
    "\n",
    "- Setting the gradient of objective to zero\n",
    "$$\n",
    "    \\nabla f(\\boldsymbol{\\beta}) = - \\mathbf{X}' (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}) = \\mathbf{0}\n",
    "$$\n",
    "leads to the **normal equation**\n",
    "$$\n",
    "    (\\mathbf{X}' \\mathbf{X}) \\boldsymbol{\\beta} = \\mathbf{X}' \\mathbf{y}.\n",
    "$$\n",
    "\n",
    "- Is there a solution to the normal equation?\n",
    "\n",
    "    Claim: the normal equation is always consistent. Why? \n",
    "    \n",
    "- Is the solution minimizer to the least squares criterion? \n",
    "\n",
    "    Claim: any solution $\\hat{\\mathbf{b}}$ to the normal equation minimizes the least squares criterion.  \n",
    "    \n",
    "    Optimization argument: Any stationary point (points with zero gradient) of a convex function is a global minimum. Now the least squares criterion is convex because the Hessian $\\nabla^2 f(\\boldsymbol{\\beta}) = \\mathbf{X}' \\mathbf{X}$ is positive semidefinite. Therefore any solution to the normal equation is a stationary point and thus a global minimum. \n",
    "    \n",
    "    Direct verifcation: Let $\\tilde{\\boldsymbol{\\beta}}$ be a solution to the normal equation. For arbitrary $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$, \n",
    "\\begin{eqnarray*}\n",
    "    & & f(\\boldsymbol{\\beta}) - f(\\tilde{\\boldsymbol{\\beta}}) \\\\\n",
    "    &=& \\frac 12 \\|\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}\\|^2 - \\frac 12 \\|\\mathbf{y} - \\mathbf{X} \\tilde{\\boldsymbol{\\beta}}\\|^2 \\\\\n",
    "    &=& \\left( \\frac 12 \\mathbf{y}' \\mathbf{y} - \\mathbf{y}' \\mathbf{X} \\boldsymbol{\\beta} + \\frac 12 \\boldsymbol{\\beta}' \\mathbf{X}' \\mathbf{X} \\boldsymbol{\\beta} \\right) - \\left( \\frac 12 \\mathbf{y}' \\mathbf{y} - \\mathbf{y}' \\mathbf{X} \\tilde{\\boldsymbol{\\beta}} + \\frac 12 \\tilde{\\boldsymbol{\\beta}}' \\mathbf{X}' \\mathbf{X} \\tilde{\\boldsymbol{\\beta}} \\right) \\\\\n",
    "    &=& - \\mathbf{y}' \\mathbf{X} (\\boldsymbol{\\beta} - \\tilde{\\boldsymbol{\\beta}}) + \\frac 12 \\boldsymbol{\\beta}' \\mathbf{X}' \\mathbf{X} \\boldsymbol{\\beta} - \\frac 12 \\tilde{\\boldsymbol{\\beta}}' \\mathbf{X}' \\mathbf{X} \\tilde{\\boldsymbol{\\beta}} \\\\\n",
    "    &=& - \\tilde{\\boldsymbol{\\beta}}' \\mathbf{X}' \\mathbf{X} (\\boldsymbol{\\beta} - \\tilde{\\boldsymbol{\\beta}}) + \\frac 12 \\boldsymbol{\\beta}' \\mathbf{X}' \\mathbf{X} \\boldsymbol{\\beta} - \\frac 12 \\tilde{\\boldsymbol{\\beta}}' \\mathbf{X}' \\mathbf{X} \\tilde{\\boldsymbol{\\beta}} \\\\\n",
    "    &=& \\frac 12 \\tilde{\\boldsymbol{\\beta}}' \\mathbf{X}' \\mathbf{X} \\tilde{\\boldsymbol{\\beta}} - \\tilde{\\boldsymbol{\\beta}}' \\mathbf{X}' \\mathbf{X} \\boldsymbol{\\beta} + \\frac 12 \\boldsymbol{\\beta}' \\mathbf{X}' \\mathbf{X} \\boldsymbol{\\beta} \\\\\n",
    "    &=& \\frac 12 (\\tilde{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})' \\mathbf{X}' \\mathbf{X} (\\tilde{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta}) \\\\\n",
    "    &=& \\frac 12 \\|\\mathbf{X} (\\tilde{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})\\|^2 \\\\\n",
    "    &\\ge& 0.\n",
    "\\end{eqnarray*}\n",
    "Therefore $\\tilde{\\boldsymbol{\\beta}}$ must be a global minimum of the least squares criterion $f(\\boldsymbol{\\beta})$.\n",
    "\n",
    "- When is the solution to the normal equation unique?  \n",
    "\n",
    "    The least squares solution is **unique** if and only if $\\mathbf{X}' \\mathbf{X}$ is non-singular if and only if $\\mathbf{X}$ has full column rank.\n",
    "    \n",
    "- In general, we can characterize the set of least squares solutions as\n",
    "$$\n",
    "    \\tilde{\\boldsymbol{\\beta}}(\\mathbf{q}) = (\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}' \\mathbf{y} + [\\mathbf{I}_p - (\\mathbf{X}' \\mathbf{X})^- (\\mathbf{X}' \\mathbf{X})] \\mathbf{q},\n",
    "$$\n",
    "where $\\mathbf{q} \\in \\mathbb{R}^q$ is arbitrary. A specific solution is\n",
    "$$\n",
    "    \\tilde{\\boldsymbol{\\beta}} = (\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}' \\mathbf{y}\n",
    "$$\n",
    "with **fitted values**\n",
    "$$\n",
    "    \\hat{\\mathbf{y}} = \\mathbf{X} \\tilde{\\boldsymbol{\\beta}} = \\mathbf{X} (\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}' \\mathbf{y}.\n",
    "$$\n",
    "\n",
    "- $(\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}'$ is a generalized inverse of $\\mathbf{X}$.\n",
    "\n",
    "    Proof: We need to show $\\mathbf{X} (\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}' \\mathbf{X} = \\mathbf{X}$, or equivalently $\\mathbf{X} (\\mathbf{I}_p - (\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}' \\mathbf{X}) = \\mathbf{O}$. But earlier we showed $\\mathcal{C}(\\mathbf{I}_p - (\\mathbf{X}' \\mathbf{X})^- \\mathbf{X}' \\mathbf{X}) = \\mathcal{N}(\\mathbf{X}' \\mathbf{X})$ and $\\mathcal{N}(\\mathbf{X}' \\mathbf{X}) = \\mathcal{N}(\\mathbf{X})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection\n",
    "\n",
    "- $\\mathbf{A} \\mathbf{A}^-$ is a projector into the column space $\\mathcal{C}(\\mathbf{A})$ along $\\mathcal{N}(\\mathbf{A}) = \\mathcal{C}(\\mathbf{I} - \\mathbf{A} \\mathbf{A}^-)$. \n",
    "\n",
    "    Proof: $\\mathbf{A} \\mathbf{A}^-$ is idempotent because $\\mathbf{A} \\mathbf{A}^- \\mathbf{A} \\mathbf{A}^- = \\mathbf{A} \\mathbf{A}^-$. Thus it projects into $\\mathcal{C}(\\mathbf{A} \\mathbf{A}^-)$, which we have shown to be equal to $\\mathcal{C}(\\mathbf{A})$. \n",
    "    \n",
    "- $\\mathbf{I}_n - \\mathbf{A}^- \\mathbf{A}$ is a projector into the null space $\\mathcal{N}(\\mathbf{A})$ along $\\mathcal{C}(\\mathbf{A})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of generalized inverses\n",
    "\n",
    "<img src=\"./three_projs.png\" width=600 align=\"center\"/>\n",
    "\n",
    "- Let\n",
    "$$\n",
    "    \\mathbf{A} = \\begin{pmatrix} \n",
    "    1 \\\\ 2\n",
    "    \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 1}.\n",
    "$$\n",
    "\n",
    "- **What are generalized inverses of $\\mathbf{A}$?**  \n",
    "Let\n",
    "$$\n",
    "\\mathbf{A}^- = (u,  v).\n",
    "$$\n",
    "By definition of generalized inverse, we want $\\mathbf{A} \\mathbf{A}^- \\mathbf{A} = \\mathbf{A}$. That is\n",
    "\\begin{eqnarray*}\n",
    "    & & \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} u, v \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\\\\n",
    "    &=& (u + 2v) \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\\\\n",
    "    &=& \\begin{pmatrix} u + 2v \\\\ 2u + 4v \\end{pmatrix} \\\\\n",
    "    &=& \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix},\n",
    "\\end{eqnarray*}\n",
    "leading to the constraint $u + 2v = 1$, or, $v = (1-u)/2$. Thus any value of $u$ gives a generalized inverse\n",
    "$$\n",
    "    \\mathbf{A}_u^- = \\begin{pmatrix} u, \\frac{1-u}{2} \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "- **Visualize $\\mathbf{A} \\mathbf{A}^-$.** \n",
    "\n",
    "    - Take $u = 0$, then\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{A}_0^- = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} 0, \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 0 & \\frac 12 \\\\ 0 & 1 \\end{pmatrix}.\n",
    "$$\n",
    "Let's see how $\\mathbf{A} \\mathbf{A}_0^-$ acts on a vector $\\mathbf{x} \\in \\mathbb{R}^2$:\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{A}_0^- \\mathbf{x} = \\begin{pmatrix} 0 & \\frac 12 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} \\frac{x_2}{2} \\\\ x_2 \\end{pmatrix} = x_2 \\begin{pmatrix} \\frac 12 \\\\ 1 \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "    - Take $u = 1$, then\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{A}_1^- = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} 1, 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 2 & 0 \\end{pmatrix}.\n",
    "$$\n",
    "Let's see how $\\mathbf{A} \\mathbf{A}_1^-$ acts on a vector $\\mathbf{x} \\in \\mathbb{R}^2$:\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{A}_1^- \\mathbf{x} = \\begin{pmatrix} 1 & 0 \\\\ 2 & 0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} x_1 \\\\ 2x_1 \\end{pmatrix} = x_1 \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "    - Take $u = \\frac 15$ to make $\\mathbf{A} \\mathbf{A}_u^-$ symmetric:\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{A}_{1/5}^- = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} \\frac 15, \\frac 25 \\end{pmatrix} = \\begin{pmatrix} 1/5 & 2/5 \\\\ 2/5 & 4/5 \\end{pmatrix}.\n",
    "$$\n",
    "Let's see how $\\mathbf{A} \\mathbf{A}_{1/5}^-$ acts on a vector $\\mathbf{x} \\in \\mathbb{R}^2$:\n",
    "$$\n",
    "    \\mathbf{A} \\mathbf{A}_{1/5}^- \\mathbf{x} = \\begin{pmatrix} 1/5 & 2/5 \\\\ 2/5 & 4/5 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} \\frac{x_1 + 2x_2}{5} \\\\ \\frac{2x_1 + 4x_2}{5} \\end{pmatrix} = \\frac{x_1 + 2x_2}{5} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
